linuxのバージョンを確認するコマンド
```
cat /etc/lsb-release

DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=18.04
DISTRIB_CODENAME=bionic
DISTRIB_DESCRIPTION="Ubuntu 18.04.5 LTS"
```

ubuntuにsqlite3を入れるコマンド
```sudo apt install sqlite3```


ファイル数カウントコマンド
```find . -type f | wc -l```


sqlite3操作コマンド
```sqlite3 trajectory.db

ls /home/fumiyuki/workspace/PCT/tools/accurate_analysis/
cp /home/fumiyuki/workspace/PCT/tools/accurate_analysis/rand_acc_results.bin ./tools/accurate_analysis/
ls /home/fumiyuki/workspace/PCT/succinct-trie/

0000000000000000,付加情報1,付加情報2,付加情報3

makeするときのコマンド
QUERY_SIZE=1439 ENCODEDVALUE_SIZE=8 FEATURE="fsa st" make

QUERY_SIZE=1439 ENCODEDVALUE_SIZE=8 FEATURE="hashtable st" make

make clean && QUERY_SIZE=1439 ENCODEDVALUE_SIZE=8 FEATURE="fsa st" make

RUST_BACKTRACE=1 bin/app 10000 data/sample 2 data/sample/server.csv

ENCODEDVALUE_SIZEはハッシュかしたときの桁数、8バイトのハッシュにしてるから。もし7バイトのハッシュの時は7にする

make cleanはエラーが起こった時にやってみた方がいいかも、変えたのに変わってないとき流行った方がいいかも、環境変数の違いはmakeで感知されないからやった方がいいかも。


# 実装で私が変える必要あるところ
1. 入力のところの引数を増やす必要がある
2. 暗号化復号化の際の型を書き換える必要上がる、引数増えたから
3. 復号化したあとの入力を格納する型を書き換える
4. 出力のときに1だったら、確率を計算する処理を書いて、1の代わりに確率を出力する encoded_result_buffers.rs
5. 


encoded_result_buffer.rs->encoded_hash_table.rs->encoded_dictionary_buffer.rs


PCT/app/src/main.rs入出力は流石にここか？
でもなんで私はenclaveをみているのじゃ？


付加情報の型

年代、感染歴、ワクチン接種歴、マスク着用の有無

多分risk_levelをうまいこと確率にすることができたら良さげ。


```debug
[1, 164, 81, 204, 48, 89, 37, 19]

 81, 205, 16, 9, 72, 179], [1, 164, 81, 205, 16, 9, 72, 179]] will print!
[HashSet] r_i size = 120 bytes
[HashSet] r_i size = 72 bytes
```

serialized

objectをバイナリ化する作業

バイナリからobjectを生成する作業をdeserialized

sgxに渡すときはバイナリ化して渡さなくてはいけなくて、serializeが必要なんだけど、sgxの中でdeserializedして、もともとと同じ奴が得られるはずなんだけど。


hashtableをバイナリ化する

```
01a451cc30592513, 10(,20,30以上), 0(1), 0(1,2,3), 0(1)
0:10代以下
1:10代
2:20代
3:30代
4:40以上

01a451cc30592513, 10,0,0,0,      u8はunsigned intが8個並んでる奴

struct RAW_DATA{
    hash:vec<u8>,
    age: u8,
    infected: u8,
    vaccine: u8,
    mask: u8
}

impl RAW_DATA{
    serialize
    (deserializeはいっかいだけだからまあそのまま描いてもいい)
}
vec<RAW_DATA>
01a451cc3059251310000
10を1バイト(=u8)の16進数で表すと0a, ハッシュ値が16

sgxにloadするときは一つのバイナリにする必要がある
つまり、最終的に一つのu8のベクトルにする
そのためには、RAW_DATAにあるserialized(10000のいち行だけをシリアライズ)を読み込んで、ループさせて一つのu8のベクトルに合体させる

sgxの中では、u8のベクトルを受け取って、区切ってdeserializeする。

# TODO Rust-analyzerをうまいことセッティング。
cargo.tomlが一番上に来るようにプロジェクトをセットする
vscodeで開くディレクトリを今のディレクトリじゃないやつにする！？

// hashに追加するよりはhashをコピーして、コピーしたそれにくっつけるだけでserializedできる

deserializeは8,1,1,1,1みたいな感じで引き剥がす？
let query_id = query_id_from_u8(&response[i*RESPONSE_DATA_SIZE_U8..i*RESPONSE_DATA_SIZE_U8+QUERY_ID_SIZE_U8]);
let result = query_result_from_u8(result.as_slice());
らへんの情報でdeserializedできる。

sgxにデータをloadするところ

STEP***
csvデータをRAW_DATAに読み込む、これをu8のバイナリにする。共通鍵を使って、バイナリを暗号化して、
sgxにデータを渡す。sgxの中で復号化して、デシリアライズして、hash_tableにどんどんいれていく。keyをハッシュ値、valueを付加情報として入れる。(containsとか基本的に同じだと思うけど、その辺の調整が必要かも？)

```


move occurs because `line` has type `std::result::Result<std::string::String, std::io::Error>`, which does not implement the `Copy` trait
&lineの型
&core::result::Result<alloc::string::String, std::io::error::Error>

&hashの型
&alloc::string::String

/home/cao/work/PCT/enclave/Enclave.edl


現状
hash tableでの、server側のデータの格納がうまくいっていないなう。->いけた、けどえーと、構造体の型とかもうちょい可読性あってもいいかもw



client_id
1,2,3,4が接触するように作ってある

```
root@c624d50ecaa7:~/sgx/samplecode/PCT# RUST_BACKTRACE=full bin/app 10000 data/test 6 data/test/server.csv
[HashSet] r_i size = 128 bytes
init_enclave...
 Init Enclave Successful 2!
[SGX CLOCK] buffers initialize:  0.000028 seconds
[SGX CLOCK] reading:  0.000614 seconds
[SGX CLOCK] decrypt each queries:  0.000551 seconds
[SGX CLOCK] store queies:  0.000649 seconds
[SGX CLOCK] whole:  0.001962 seconds
[SGX CLOCK] central data decryption:  0.000018 seconds
positive result queryIds: [(1, 0.8), (2, 0.8), (3, 0.8), (4, 0.8)]
[Clocker] Distribute central data:  0.000365 seconds
[Clocker] ECALL init_enclave:  2.143779 seconds
[Clocker] ECALL upload_query_data:  0.002649 seconds
[Clocker] ECALL private_contact_trace:  0.000335 seconds
[Clocker] ECALL get_result:  0.000025 seconds
[Clocker] Read Query Data:  0.008982 seconds
[Clocker] Read Central Data:  0.001714 seconds
```

data: {1: [[1, 1, 1, 1], [2, 2, 2, 2]], 3: [[1, 1, 1, 1]], 2: [[1, 1, 1, 1]], 4: [[1, 1, 1, 1]]}
client_data: {3: [[2, 1, 1, 0]], 2: [[2, 1, 3, 0]], 4: [[3, 1, 2, 1]], 1: [[1, 0, 0, 0], [1, 0, 0, 0]]} 



******データのハッシュ値は時間が違うから全部値が違うという前提の元書いてる。


```
root@c624d50ecaa7:~/sgx/samplecode/PCT# RUST_BACKTRACE=full bin/app 10000 data/test 6 data/test/server_test.csv
[HashSet] r_i size = 17288 bytes
init_enclave...
 Init Enclave Successful 2!
[SGX CLOCK] buffers initialize:  0.000042 seconds
[SGX CLOCK] reading:  0.000653 seconds
[SGX CLOCK] decrypt each queries:  0.000565 seconds
[SGX CLOCK] store queies:  0.000627 seconds
[SGX CLOCK] whole:  0.002049 seconds
[SGX CLOCK] central data decryption:  0.000074 seconds
positive result queryIds: [(1, 0.0064800004), (2, 0.00047250008), (3, 0.0011812502), (4, 0.00023625002)]
[Clocker] ECALL private_contact_trace:  0.000497 seconds
[Clocker] ECALL upload_query_data:  0.002721 seconds
[Clocker] ECALL init_enclave:  2.151883 seconds
[Clocker] Distribute central data:  0.000384 seconds
[Clocker] Read Central Data:  0.001674 seconds
[Clocker] ECALL get_result:  0.000066 seconds
[Clocker] Read Query Data:  0.009244 seconds
```


addi: room
0 :default, ワイルドカード的なノリ
1 :
2
3
4
...


QUERY_SIZE=1439 ENCODEDVALUE_SIZE=13 FEATURE="hashtable" make
RUST_BACKTRACE=full bin/app 10000 data/test2 6 data/test2/server_test.csv


self EncodedResultBuffer { data: {4: [[1, 1, 1, 1, 0]], 2: [[1, 1, 1, 1, 0]], 3: [[1, 1, 1, 1, 0]], 1: [[1, 1, 1, 1, 0]]}, client_data: {2: [[2, 1, 3, 0, 0]], 4: [[3, 1, 2, 1, 0]], 1: [[1, 0, 0, 0, 0]], 3: [[2, 1, 1, 0, 0]]} } will print!
positive result queryIds: [(1, 0.00504), (2, 0.00047250008), (3, 0.0011812502), (4, 0.00023625002)]
positive result queryIds: [(1, 0.00504), (2, 0.00047250008), (3, 0.0011812502), (4, 0.00023625002)]


self EncodedResultBuffer { data: {4: [[1, 1, 1, 1, 0]], 1: [[1, 1, 1, 1, 0], [1, 1, 1, 1, 0], [1, 1, 1, 1, 0]], 3: [[1, 1, 1, 1, 0]], 2: [[1, 1, 1, 1, 0]]}, client_data: {1: [[1, 0, 0, 0, 0], [1, 0, 2, 1, 0], [1, 1, 3, 1, 0]], 3: [[2, 1, 1, 0, 0]], 4: [[3, 1, 2, 1, 0]], 2: [[2, 1, 3, 0, 0]]} } will print!
positive result queryIds: [(1, 0.00504), (2, 0.00047250008), (3, 0.0011812502), (4, 0.00023625002)]

positive result queryIds: [(1, 0.00050400005), (2, 0.00047250008), (3, 0.0011812502), (4, 0.00023625002)]



TODO: 密閉空間のやつ、mergeするかどうか。


QUERY_SIZE=1439 ENCODEDVALUE_SIZE=12 FEATURE="hashtable" make


RUST_BACKTRACE=1 bin/app 10000 tools/trajectory_hash/data_expanded/tokyo 2 tools/trajectory_hash/data_expanded/tokyo/server-14000-24-22.csv

PCT/tools/trajectory_hash/data/random/client-24-22-999.csv
/home/cao/work/PCT/tools/trajectory_hash/data/random/server-1000-24-22.csv